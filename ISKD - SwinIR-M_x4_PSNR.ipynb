{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPfOtuaToqZCtOd2Ub46K/N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Day 1 â€“ Dataset Curation & Blurring Pipeline**"],"metadata":{"id":"LjU4wbk5gaGs"}},{"cell_type":"markdown","source":["### **Mount Google Drive and Setup Paths**"],"metadata":{"id":"sc1COyVUgwBI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybpQyCOIfVtP","executionInfo":{"status":"ok","timestamp":1750778001091,"user_tz":-330,"elapsed":28431,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"b7d16e5c-14cd-4684-dde9-27479cf48266"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Folder structure created.\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set project root directory\n","project_root = '/content/drive/MyDrive/ImageSharpening_KD'\n","data_root = os.path.join(project_root, 'data')\n","\n","# Dataset directories\n","dirs = [\n","    'whole_dataset',\n","    'sharp/train/train', 'sharp/train/test', 'sharp/benchmark',\n","    'blurry/train/train', 'blurry/train/test', 'blurry/benchmark'\n","]\n","\n","# Create folder structure\n","for d in dirs:\n","    os.makedirs(os.path.join(data_root, d), exist_ok=True)\n","\n","print(\"Folder structure created.\")\n"]},{"cell_type":"markdown","source":["### **Download DIV2K Dataset**"],"metadata":{"id":"X1LYKBm-g2RF"}},{"cell_type":"code","source":["!wget -O DIV2K_train_HR.zip https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","!unzip -q DIV2K_train_HR.zip -d temp_DIV2K\n","\n","import shutil\n","\n","# Move all original PNGs to whole_dataset\n","whole_dataset_path = os.path.join(data_root, 'whole_dataset')\n","for file in os.listdir('temp_DIV2K/DIV2K_train_HR'):\n","    shutil.move(f'temp_DIV2K/DIV2K_train_HR/{file}', whole_dataset_path)\n","\n","print(\"DIV2K images moved to whole_dataset/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lK83iS3ugKIF","executionInfo":{"status":"ok","timestamp":1750778326174,"user_tz":-330,"elapsed":293533,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"7c09b983-0193-4151-d8a7-096b585a93af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-06-24 15:13:54--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n","Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3530603713 (3.3G) [application/zip]\n","Saving to: â€˜DIV2K_train_HR.zipâ€™\n","\n","DIV2K_train_HR.zip  100%[===================>]   3.29G  19.6MB/s    in 2m 58s  \n","\n","2025-06-24 15:16:53 (18.9 MB/s) - â€˜DIV2K_train_HR.zipâ€™ saved [3530603713/3530603713]\n","\n","DIV2K images moved to whole_dataset/\n"]}]},{"cell_type":"markdown","source":["### **Blur and Crop to Patches (256x256)**"],"metadata":{"id":"Hl7qA7IIg8u3"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from PIL import Image\n","import random\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","# Configuration\n","PATCH_SIZE = 256\n","JPEG_QUALITY = 90\n","\n","# Load image paths\n","image_paths = sorted([os.path.join(whole_dataset_path, img) for img in os.listdir(whole_dataset_path) if img.endswith('.png')])\n","\n","# Split: 90% train_set, 10% benchmark_set\n","train_paths, benchmark_paths = train_test_split(image_paths, test_size=0.1, random_state=42)\n","\n","# Further split train: 80% train, 20% test\n","train_split, test_split = train_test_split(train_paths, test_size=0.2, random_state=42)\n","\n","def process_and_save(image_path, sharp_dir, blurry_dir):\n","    img = cv2.imread(image_path)\n","    h, w, _ = img.shape\n","\n","    # Crop into non-overlapping 256x256 patches\n","    for i in range(0, h - PATCH_SIZE + 1, PATCH_SIZE):\n","        for j in range(0, w - PATCH_SIZE + 1, PATCH_SIZE):\n","            patch = img[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n","\n","            # Save sharp patch\n","            sharp_img = Image.fromarray(cv2.cvtColor(patch, cv2.COLOR_BGR2RGB))\n","\n","            # Generate blurry patch via down-up scaling\n","            downscaled = cv2.resize(patch, (PATCH_SIZE//4, PATCH_SIZE//4), interpolation=cv2.INTER_CUBIC)\n","            upscaled = cv2.resize(downscaled, (PATCH_SIZE, PATCH_SIZE), interpolation=cv2.INTER_CUBIC)\n","            blurry_img = Image.fromarray(cv2.cvtColor(upscaled, cv2.COLOR_BGR2RGB))\n","\n","            # Use image name + location as ID\n","            name = os.path.basename(image_path).replace('.png', f'_{i}_{j}.jpg')\n","            sharp_img.save(os.path.join(sharp_dir, name), quality=JPEG_QUALITY)\n","            blurry_img.save(os.path.join(blurry_dir, name), quality=JPEG_QUALITY)\n","\n","# Process each split\n","for path in tqdm(train_split, desc=\"Processing training patches\"):\n","    process_and_save(path,\n","                     os.path.join(data_root, 'sharp/train/train'),\n","                     os.path.join(data_root, 'blurry/train/train'))\n","\n","for path in tqdm(test_split, desc=\"Processing testing patches\"):\n","    process_and_save(path,\n","                     os.path.join(data_root, 'sharp/train/test'),\n","                     os.path.join(data_root, 'blurry/train/test'))\n","\n","for path in tqdm(benchmark_paths, desc=\"Processing benchmark patches\"):\n","    process_and_save(path,\n","                     os.path.join(data_root, 'sharp/benchmark'),\n","                     os.path.join(data_root, 'blurry/benchmark'))\n","\n","print(\"âœ… All sharp-blurry patches created and stored.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugH5cCUdhCC9","executionInfo":{"status":"ok","timestamp":1750779616488,"user_tz":-330,"elapsed":1121137,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"ccde6df9-764f-4648-dbef-af482ee11185"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing training patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [13:12<00:00,  1.38s/it]\n","Processing testing patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144/144 [03:16<00:00,  1.37s/it]\n","Processing benchmark patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:06<00:00,  1.58s/it]"]},{"output_type":"stream","name":"stdout","text":["âœ… All sharp-blurry patches created and stored.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### **Dataset Structure & Image Count Validation**"],"metadata":{"id":"Aj6-C0d5mUb9"}},{"cell_type":"code","source":["import os\n","\n","# Define dataset folders to check\n","folder_check_list = [\n","    'sharp/train/train',\n","    'sharp/train/test',\n","    'sharp/benchmark',\n","    'blurry/train/train',\n","    'blurry/train/test',\n","    'blurry/benchmark'\n","]\n","\n","print(\"ðŸ” Verifying dataset storage in Google Drive...\\n\")\n","\n","total_images = 0\n","for folder in folder_check_list:\n","    path = os.path.join(data_root, folder)\n","    images = [f for f in os.listdir(path) if f.endswith('.jpg')]\n","    count = len(images)\n","    total_images += count\n","    print(f\"ðŸ“ {folder:<25} â†’ {count} images\")\n","\n","print(\"\\nâœ… Total image patches saved:\", total_images)\n","\n","# Optional: check if drive path really exists (no temp fallback)\n","if \"/content/drive\" in data_root and os.path.exists(data_root):\n","    print(\"âœ… Data saved permanently in Google Drive âœ”ï¸\")\n","else:\n","    print(\"âŒ WARNING: Dataset not saved in Drive! Check mount path.\")\n","\n","# Optional: assert all folders have data\n","empty_folders = [f for f in folder_check_list if len(os.listdir(os.path.join(data_root, f))) == 0]\n","if empty_folders:\n","    print(\"\\nâš ï¸ Empty folders found:\")\n","    for f in empty_folders:\n","        print(f\"   - {f}\")\n","else:\n","    print(\"âœ… All folders contain image data.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3eDJb7LmZI2","executionInfo":{"status":"ok","timestamp":1750861210953,"user_tz":-330,"elapsed":176165,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"4092bd99-8da0-4651-9cc5-a0ab91b55c22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ” Verifying dataset storage in Google Drive...\n","\n","ðŸ“ sharp/train/train         â†’ 20111 images\n","ðŸ“ sharp/train/test          â†’ 5005 images\n","ðŸ“ sharp/benchmark           â†’ 2842 images\n","ðŸ“ blurry/train/train        â†’ 20111 images\n","ðŸ“ blurry/train/test         â†’ 5005 images\n","ðŸ“ blurry/benchmark          â†’ 2842 images\n","\n","âœ… Total image patches saved: 55916\n","âœ… Data saved permanently in Google Drive âœ”ï¸\n","âœ… All folders contain image data.\n"]}]},{"cell_type":"markdown","source":["# **DAY 2 â€“ SwinIR Teacher Inference**"],"metadata":{"id":"dZt6_8BN7IAv"}},{"cell_type":"markdown","source":["### **Enable GPU**"],"metadata":{"id":"5RoElLhK7N-P"}},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available(), torch.cuda.get_device_name(0)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ku48BA-v6fRP","executionInfo":{"status":"ok","timestamp":1750862225799,"user_tz":-330,"elapsed":2139,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"fe7f0fd6-737d-4128-89dd-cfc306379416"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, 'Tesla T4')"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["!pip install -q basicsr einops opencv-python scikit-image Pillow tqdm\n","\n","# Clone only if not already cloned\n","import os\n","if not os.path.exists('/content/SwinIR'):\n","    !git clone https://github.com/JingyunLiang/SwinIR.git\n","%cd /content/SwinIR\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2I3aleVVhWnz","executionInfo":{"status":"ok","timestamp":1750862311088,"user_tz":-330,"elapsed":5105,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"a6b86482-044a-4441-cbb4-122c606eded9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/SwinIR\n"]}]},{"cell_type":"markdown","source":["### **Set Up Paths & Output Folders**"],"metadata":{"id":"T3VNtf447S9t"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Mount Drive\n","drive.mount('/content/drive')\n","\n","# Project paths\n","project_root = '/content/drive/MyDrive/ImageSharpening_KD'\n","data_root = os.path.join(project_root, 'data')\n","output_root = os.path.join(project_root, 'outputs/teacher_output')\n","\n","# Ensure output directories exist\n","os.makedirs(os.path.join(output_root, 'train'), exist_ok=True)\n","os.makedirs(os.path.join(output_root, 'test'), exist_ok=True)\n","os.makedirs(os.path.join(output_root, 'benchmark'), exist_ok=True)\n"],"metadata":{"id":"vA1rh3KG7X0b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750862338921,"user_tz":-330,"elapsed":4028,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"d6bd2836-d128-431e-e47b-d031b4f702c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from basicsr.archs.swinir_arch import SwinIR\n","\n","model = SwinIR(\n","    upscale=4,\n","    in_chans=3,\n","    img_size=64,\n","    window_size=8,\n","    img_range=1.0,\n","    depths=[6, 6, 6, 6, 6, 6],\n","    embed_dim=180,\n","    num_heads=[6, 6, 6, 6, 6, 6],\n","    mlp_ratio=2,\n","    upsampler='nearest+conv',  # âœ… THIS is the key fix\n","    resi_connection='1conv'\n",")\n"],"metadata":{"id":"23DSpVzyh1Sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load checkpoint\n","checkpoint = torch.load(model_path, map_location=device)\n","checkpoint = checkpoint.get('params_ema', checkpoint)  # fallback if no 'params_ema'\n","\n","model.load_state_dict(checkpoint, strict=True)\n","model.eval().to(device)\n","\n","print(\"âœ… Model loaded with 'nearest+conv' upsampler.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_AsQocU_iZcw","executionInfo":{"status":"ok","timestamp":1750862505437,"user_tz":-330,"elapsed":305,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"9497f439-3c61-4592-fba5-1840a9a6605b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Model loaded with 'nearest+conv' upsampler.\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from tqdm import tqdm\n","import torch\n","import torchvision.transforms as transforms\n","import numpy as np\n","from skimage.metrics import structural_similarity as compare_ssim\n","from skimage.metrics import peak_signal_noise_ratio as compare_psnr"],"metadata":{"id":"mdB931jokzWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Define Paths & Transforms**"],"metadata":{"id":"AXJ4PcCGjDvT"}},{"cell_type":"code","source":["project_root = '/content/drive/MyDrive/ImageSharpening_KD'\n","data_root = os.path.join(project_root, 'data')\n","output_root = os.path.join(project_root, 'outputs/teacher_output')\n","log_dir = os.path.join(project_root, 'logs')\n","os.makedirs(log_dir, exist_ok=True)\n","\n","input_folders = {\n","    'train': os.path.join(data_root, 'blurry/train/train'),\n","    'test': os.path.join(data_root, 'blurry/train/test'),\n","    'benchmark': os.path.join(data_root, 'blurry/benchmark')\n","}\n","\n","gt_folders = {\n","    'train': os.path.join(data_root, 'sharp/train/train'),\n","    'test': os.path.join(data_root, 'sharp/train/test'),\n","    'benchmark': os.path.join(data_root, 'sharp/benchmark')\n","}\n","\n","output_folders = {\n","    'train': os.path.join(output_root, 'train'),\n","    'test': os.path.join(output_root, 'test'),\n","    'benchmark': os.path.join(output_root, 'benchmark')\n","}\n","\n","# Create output folders if they don't exist\n","for folder in output_folders.values():\n","    os.makedirs(folder, exist_ok=True)"],"metadata":{"id":"GlzmMgXQirQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_tensor = transforms.ToTensor()\n","to_pil = transforms.ToPILImage()\n"],"metadata":{"id":"HdQMoZIfkNZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Define the Inference Function**"],"metadata":{"id":"3Rr0fCp-jKkg"}},{"cell_type":"code","source":["def run_inference(input_dir, output_dir, gt_dir, max_images=100, log_file=None):\n","    files = sorted([f for f in os.listdir(input_dir) if f.endswith('.jpg')])[:max_images]\n","\n","    total_ssim = 0\n","    total_psnr = 0\n","\n","    for fname in tqdm(files, desc=f\"Processing {os.path.basename(input_dir)}\"):\n","        # Load input and GT\n","        blurry = Image.open(os.path.join(input_dir, fname)).convert('RGB')\n","        sharp_gt = Image.open(os.path.join(gt_dir, fname)).convert('RGB')\n","\n","        # Convert to tensor\n","        blurry_tensor = to_tensor(blurry).unsqueeze(0).to(device)\n","\n","        # Run SwinIR model\n","        with torch.no_grad():\n","            pred_tensor = model(blurry_tensor).squeeze().cpu().clamp(0, 1)\n","\n","        # Convert output to image\n","        pred_img = to_pil(pred_tensor)\n","        pred_img.save(os.path.join(output_dir, fname), quality=95)\n","\n","        # ðŸ” Resize GT to match SwinIR output size\n","        sharp_gt_resized = sharp_gt.resize(pred_img.size, Image.BICUBIC)\n","\n","        # Convert both to numpy for SSIM/PSNR\n","        pred_np = np.array(pred_img)\n","        gt_np = np.array(sharp_gt_resized)\n","\n","        # Calculate metrics\n","        ssim_val = compare_ssim(pred_np, gt_np, channel_axis=-1)\n","        psnr_val = compare_psnr(gt_np, pred_np)\n","\n","        total_ssim += ssim_val\n","        total_psnr += psnr_val\n","\n","    avg_ssim = total_ssim / len(files)\n","    avg_psnr = total_psnr / len(files)\n","\n","    print(f\"\\nðŸ“Š {os.path.basename(output_dir).capitalize()} Results â†’ SSIM: {avg_ssim:.4f} | PSNR: {avg_psnr:.2f} dB\")\n","\n","    if log_file:\n","        with open(log_file, 'w') as f:\n","            f.write(f\"SSIM: {avg_ssim:.4f}\\nPSNR: {avg_psnr:.2f} dB\\n\")\n","\n","    return avg_ssim, avg_psnr\n"],"metadata":{"id":"agMdrXHciuDI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Run Inference on All Sets**"],"metadata":{"id":"hGwYUbJxjRFE"}},{"cell_type":"code","source":["# Safe batch sizes for Colab Free Tier\n","run_inference(\n","    input_folders['train'], output_folders['train'], gt_folders['train'], max_images=500\n",")\n","\n","run_inference(\n","    input_folders['test'], output_folders['test'], gt_folders['test'], max_images=200\n",")\n","\n","run_inference(\n","    input_folders['benchmark'],\n","    output_folders['benchmark'],\n","    gt_folders['benchmark'],\n","    max_images=100,\n","    log_file=os.path.join(log_dir, 'teacher_benchmark_scores.txt')\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvgg2viUiwcs","executionInfo":{"status":"ok","timestamp":1750865485997,"user_tz":-330,"elapsed":2272217,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"1cd6e79a-c9b4-45de-82df-a6c7b3fb15a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [23:03<00:00,  2.77s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š Train Results â†’ SSIM: 0.7238 | PSNR: 24.61 dB\n"]},{"output_type":"stream","name":"stderr","text":["Processing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [09:34<00:00,  2.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š Test Results â†’ SSIM: 0.7851 | PSNR: 28.57 dB\n"]},{"output_type":"stream","name":"stderr","text":["Processing benchmark: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [05:12<00:00,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š Benchmark Results â†’ SSIM: 0.7549 | PSNR: 26.53 dB\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.7549359185850991, 26.530614450982355)"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# **Day 3 â€“ Student Model (Mini-UNet) + Baseline L1 Training**"],"metadata":{"id":"oIGWGOMCxMit"}},{"cell_type":"code","source":["import os\n","import sys\n","\n","# Check if Drive is already mounted\n","if not os.path.ismount('/content/drive'):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\"âœ… Drive mounted successfully.\")\n","else:\n","    print(\"ðŸ“ Drive already mounted.\")\n","\n","# Append code folder only if not already added\n","code_path = '/content/drive/MyDrive/ImageSharpening_KD/code'\n","if code_path not in sys.path:\n","    sys.path.append(code_path)\n","    print(f\"âœ… Code path added: {code_path}\")\n","else:\n","    print(f\"ðŸ“‚ Code path already in sys.path: {code_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9i5ZkjDmz5a1","executionInfo":{"status":"ok","timestamp":1750867164349,"user_tz":-330,"elapsed":124,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"acd0e24b-f630-44c6-be14-a55c075f7ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“ Drive already mounted.\n","ðŸ“‚ Code path already in sys.path: /content/drive/MyDrive/ImageSharpening_KD/code\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/ImageSharpening_KD/code/train_student.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9BCU1BY0PoG","executionInfo":{"status":"ok","timestamp":1750867648888,"user_tz":-330,"elapsed":465456,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"b4275420-79bf-4e7a-c5b1-0a7c505c4804"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg L1 Loss: 0.2897\n","Epoch 2/5 - Avg L1 Loss: 0.1643\n","Epoch 3/5 - Avg L1 Loss: 0.1167\n","Epoch 4/5 - Avg L1 Loss: 0.0822\n","Epoch 5/5 - Avg L1 Loss: 0.0788\n"]}]},{"cell_type":"markdown","source":["# **Day 4 â€“ Knowledge Distillation: Student Learns from Teacher**"],"metadata":{"id":"dCbi_A4Mq4Ap"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/ImageSharpening_KD/code')\n","\n","!python /content/drive/MyDrive/ImageSharpening_KD/code/train_distill.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AacCwAu8r--h","executionInfo":{"status":"ok","timestamp":1750916586540,"user_tz":-330,"elapsed":388331,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"22019bbe-4c46-4872-ccc5-c41960f8a470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Epoch 1/10 - Total Loss: 0.2547\n","Epoch 2/10 - Total Loss: 0.1497\n","Epoch 3/10 - Total Loss: 0.0949\n","Epoch 4/10 - Total Loss: 0.0711\n","Epoch 5/10 - Total Loss: 0.0648\n","Epoch 6/10 - Total Loss: 0.0572\n","Epoch 7/10 - Total Loss: 0.0579\n","Epoch 8/10 - Total Loss: 0.0569\n","Epoch 9/10 - Total Loss: 0.0563\n","Epoch 10/10 - Total Loss: 0.0546\n","Epoch 11/10 - Total Loss: 0.0511\n","Epoch 12/10 - Total Loss: 0.0524\n","Epoch 13/10 - Total Loss: 0.0484\n","Epoch 14/10 - Total Loss: 0.0504\n","Epoch 15/10 - Total Loss: 0.0463\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/ImageSharpening_KD/code')\n","\n","!python /content/drive/MyDrive/ImageSharpening_KD/code/evaluate_student_kd.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVVkO5w-LLsg","executionInfo":{"status":"ok","timestamp":1750941685290,"user_tz":-330,"elapsed":1373957,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"192aed58-f5c9-4c4c-850a-9719bf2c0c27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Evaluating: 100% 2842/2842 [21:51<00:00,  2.17it/s]\n","\n","ðŸ“Š Student Evaluation on Benchmark:\n","âœ… SSIM: 0.6469\n","âœ… PSNR: 24.33 dB\n"]}]},{"cell_type":"markdown","source":["## **Another appraoch for increasing SSIM SCore**"],"metadata":{"id":"xj-QeyDfHXX9"}},{"cell_type":"code","source":["from google.colab import drive\n","import sys\n","import os\n","\n","# âœ… Mount Google Drive\n","if not os.path.ismount('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Drive already mounted âœ…\")\n","\n","# âœ… Append code directory\n","code_path = '/content/drive/MyDrive/ImageSharpening_KD/code'\n","if code_path not in sys.path:\n","    sys.path.append(code_path)\n","    print(\"Code path added âœ…\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yrc00azqP-28","executionInfo":{"status":"ok","timestamp":1751176491854,"user_tz":-330,"elapsed":47918,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"536be13c-c13b-4f1e-bf79-83a1c78b8cdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Code path added âœ…\n"]}]},{"cell_type":"code","source":["# Required for perceptual loss\n","!pip install --quiet torch torchvision\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvuhY-UDQoU4","executionInfo":{"status":"ok","timestamp":1751176701255,"user_tz":-330,"elapsed":87461,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"20370bd9-2287-471c-8ab6-8204b21bf158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/ImageSharpening_KD/code/train_distill_vgg.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRD4v9ByQxdv","executionInfo":{"status":"ok","timestamp":1751178326136,"user_tz":-330,"elapsed":1623188,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"c50ca962-c299-401f-bc78-ed9f0eb5503f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100% 528M/528M [00:03<00:00, 182MB/s]\n","Epoch 1/75 - Loss: 0.5438\n","Epoch 2/75 - Loss: 0.3896\n","Epoch 3/75 - Loss: 0.3226\n","Epoch 4/75 - Loss: 0.2765\n","Epoch 5/75 - Loss: 0.2436\n","Epoch 6/75 - Loss: 0.2219\n","Epoch 7/75 - Loss: 0.2145\n","Epoch 8/75 - Loss: 0.2123\n","Epoch 9/75 - Loss: 0.2083\n","Epoch 10/75 - Loss: 0.2060\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch10.pt\n","Epoch 11/75 - Loss: 0.2041\n","Epoch 12/75 - Loss: 0.1969\n","Epoch 13/75 - Loss: 0.1997\n","Epoch 14/75 - Loss: 0.2004\n","Epoch 15/75 - Loss: 0.1976\n","Epoch 16/75 - Loss: 0.1993\n","Epoch 17/75 - Loss: 0.1978\n","Epoch 18/75 - Loss: 0.1945\n","Epoch 19/75 - Loss: 0.1924\n","Epoch 20/75 - Loss: 0.1946\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch20.pt\n","Epoch 21/75 - Loss: 0.1901\n","Epoch 22/75 - Loss: 0.1944\n","Epoch 23/75 - Loss: 0.1909\n","Epoch 24/75 - Loss: 0.1893\n","Epoch 25/75 - Loss: 0.1894\n","Epoch 26/75 - Loss: 0.1875\n","Epoch 27/75 - Loss: 0.1919\n","Epoch 28/75 - Loss: 0.1897\n","Epoch 29/75 - Loss: 0.1892\n","Epoch 30/75 - Loss: 0.1910\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch30.pt\n","Epoch 31/75 - Loss: 0.1927\n","Epoch 32/75 - Loss: 0.1835\n","Epoch 33/75 - Loss: 0.1869\n","Epoch 34/75 - Loss: 0.1879\n","Epoch 35/75 - Loss: 0.1878\n","Epoch 36/75 - Loss: 0.1866\n","Epoch 37/75 - Loss: 0.1837\n","Epoch 38/75 - Loss: 0.1864\n","Epoch 39/75 - Loss: 0.1828\n","Epoch 40/75 - Loss: 0.1868\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch40.pt\n","Epoch 41/75 - Loss: 0.1849\n","Epoch 42/75 - Loss: 0.1841\n","Epoch 43/75 - Loss: 0.1858\n","Epoch 44/75 - Loss: 0.1839\n","Epoch 45/75 - Loss: 0.1800\n","Epoch 46/75 - Loss: 0.1862\n","Epoch 47/75 - Loss: 0.1862\n","Epoch 48/75 - Loss: 0.1830\n","Epoch 49/75 - Loss: 0.1841\n","Epoch 50/75 - Loss: 0.1814\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch50.pt\n","Epoch 51/75 - Loss: 0.1828\n","Epoch 52/75 - Loss: 0.1805\n","Epoch 53/75 - Loss: 0.1817\n","Epoch 54/75 - Loss: 0.1826\n","Epoch 55/75 - Loss: 0.1801\n","Epoch 56/75 - Loss: 0.1799\n","Epoch 57/75 - Loss: 0.1821\n","Epoch 58/75 - Loss: 0.1804\n","Epoch 59/75 - Loss: 0.1776\n","Epoch 60/75 - Loss: 0.1808\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch60.pt\n","Epoch 61/75 - Loss: 0.1805\n","Epoch 62/75 - Loss: 0.1815\n","Epoch 63/75 - Loss: 0.1789\n","Epoch 64/75 - Loss: 0.1771\n","Epoch 65/75 - Loss: 0.1789\n","Epoch 66/75 - Loss: 0.1805\n","Epoch 67/75 - Loss: 0.1813\n","Epoch 68/75 - Loss: 0.1787\n","Epoch 69/75 - Loss: 0.1776\n","Epoch 70/75 - Loss: 0.1803\n","ðŸ’¾ Saved checkpoint: /content/drive/MyDrive/ImageSharpening_KD/models/student_kd_vgg_epoch70.pt\n","Epoch 71/75 - Loss: 0.1769\n","Epoch 72/75 - Loss: 0.1808\n","Epoch 73/75 - Loss: 0.1765\n","Epoch 74/75 - Loss: 0.1777\n","Epoch 75/75 - Loss: 0.1777\n","âœ… Final VGG+KD student model saved.\n","ðŸ–¼ï¸ Saved sample student output (VGG).\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/ImageSharpening_KD/code/evaluate_student_kd.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvSiW0JaXLkg","executionInfo":{"status":"ok","timestamp":1751182519734,"user_tz":-330,"elapsed":4187073,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"dc12652d-70e2-4d99-c65e-ef3be62f562f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating: 100% 2842/2842 [1:09:25<00:00,  1.47s/it]\n","\n","ðŸ“Š Student Evaluation on Benchmark:\n","âœ… SSIM: 0.6560\n","âœ… PSNR: 25.02 dB\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import sys, os\n","\n","drive.mount('/content/drive')\n","\n","# Re-append code path if needed\n","code_path = '/content/drive/MyDrive/ImageSharpening_KD/code'\n","if code_path not in sys.path:\n","    sys.path.append(code_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nJsoisByXFb","executionInfo":{"status":"ok","timestamp":1751185498497,"user_tz":-330,"elapsed":3857,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"387e05f6-4958-4d08-b713-2f2a82034c4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["sys.path.append('/content/drive/MyDrive/ImageSharpening_KD/code')\n","\n","!python /content/drive/MyDrive/ImageSharpening_KD/code/batch_test_show.py"],"metadata":{"id":"74834ayGypBq","executionInfo":{"status":"ok","timestamp":1751185544310,"user_tz":-330,"elapsed":14383,"user":{"displayName":"Music World","userId":"17365023153281436921"}},"outputId":"8c9f5263-6211-452d-ecb1-9559f86a98da","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ” Processing blurry images...\n","1.jpg â†’ SSIM: 0.6614\n","Figure(1200x400)\n","2.jpg â†’ SSIM: 0.7611\n","Figure(1200x400)\n","3.jpg â†’ SSIM: 0.7052\n","Figure(1200x400)\n","4.jpg â†’ SSIM: 0.6793\n","Figure(1200x400)\n","5.jpg â†’ SSIM: 0.7354\n","Figure(1200x400)\n"]}]},{"cell_type":"markdown","source":["### **Exporting SwinIR Project Without Dataset**"],"metadata":{"id":"Yg2SG-2sHF6J"}}]}